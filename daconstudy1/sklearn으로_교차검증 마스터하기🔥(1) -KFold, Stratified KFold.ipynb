{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "교차검증1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "안녕하세요! 데이크루 1기로 활동 중인 sssssun입니다!\n",
        "\n",
        "계속해서 sklearn을 활용한 머신러닝에 대해 공부해볼텐데요. \n",
        "\n",
        "오늘은 **교차검증(Cross Validaiton)**에 대해 포스팅해보겠습니다.\n",
        "\n",
        "저도 처음 교차검증을 배워보며 공부한 내용을 작성하는 것이기 때문에 다른 팁이나 잘못된 내용이 있다면 꼭 알려주세요😇"
      ],
      "metadata": {
        "id": "pRMcBzk_zFgB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. 교차검증을 하는 이유?**\n",
        "\n",
        "우리가 머신러닝 모델을 만들고 모델의 성능을 높이기 위해 우리는 데이터셋을 **학습용 데이터(train set)**와 **테스트용 데이터(test set)**로 나눕니다.\n",
        "\n",
        "sklearn의 경우 **train_test_split** 메서드로 과정을 수행했죠.\n",
        "\n",
        "이 경우에 우리는 결국 test data를 사용하여 모델 검증을 하게 됩니다. \n",
        "\n",
        "하지만 고정된 test set을 가지고 모델의 성능을 확인하고 파라미터를 수정하고 이 과정을 반복하면, 결국 우리가 만든 모델은 test set에만 잘 동작하는 모델이 됩니다. \n",
        "\n",
        "이렇게 머신러닝에서 test set을 과하게 잘 학습하여 다른 실제 데이터를 가지고 예측을 수행하면 정확성이 떨어지는 것을 **과적합(overfitting)**이라고 합니다.\n",
        "\n",
        "이러한 과적합의 방지를 위해 교차 검증이 필요합니다!"
      ],
      "metadata": {
        "id": "odbehITF2Ppz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. 교차 검증이란?**\n",
        "\n",
        "주어진 데이터셋에 학습된 알고리즘이 얼마나 잘 일반화되어있는지 평가하기 위한 방법입니다.\n",
        "\n",
        "데이터를 여러 번 반복해서 나누고 여러번의 모델 학습과 검증 과정을 거칩니다.\n",
        "\n",
        "교차 검증을 활용하면 데이터셋 내의 **모든 데이터를 훈련에 활용**할 수 있고, 모델의 **성능과 정확도를 더 향상**시킬 수 있으며 좀 더 **일반화된 모델**을 만들 수 있습니다.\n",
        "\n",
        "또한 데이터 부족으로 인한 underfitting을 방지할 수 있고, test set이 편중되는 것을 방지할 수 있습니다.\n"
      ],
      "metadata": {
        "id": "6Lmz1isW5TW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "오늘은 교차검증 방법 중에 가장 대중화된 **K-Fold Cross Validation(k-겹 교차 검증)**과 **Stratified K-Fold Cross Validation(계층별 k-겹 교차 검증)**을 다뤄보겠습니다.\n",
        "\n",
        "[sklearn으로 파이썬 머신러닝 입문하기🔥 - 분류 모델](https://dacon.io/codeshare/4421) <- 이전 포스팅에서 구현했던 iris data set을 활용한 의사결정나무 분류 모델을 이용하겠습니다!"
      ],
      "metadata": {
        "id": "XrMKO2Kh9MBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "jAqtwmyc_wXS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "필요한 라이브러리들을 import 해주었습니다."
      ],
      "metadata": {
        "id": "3UIskTR7-Yhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=1)\n",
        "dt_clf = DecisionTreeClassifier(random_state =1)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "pred = dt_clf.predict(X_test)\n",
        "round(accuracy_score(y_test, pred), 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpFSaM24-PL-",
        "outputId": "fa373e09-a5d4-483c-ca23-86610373df8f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9556"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "의사결정나무 모델을 구현하여 모델의 정확도를 산출해보았습니다.\n",
        "\n",
        "0.9556이 나오네요.\n",
        "\n",
        "이제 교차검증을 활용해보겠습니다."
      ],
      "metadata": {
        "id": "puTnlJC1AO6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. K-Fold Cross Validation(k-겹 교차 검증)**\n",
        "\n",
        "\n",
        "k겹 교차 검증에서는 먼저 우리가 아는 것처럼 전체 데이터셋을 **train set** 과 **test set**으로 나눠줍니다.\n",
        "\n",
        "그리고 train set을 **k개의 폴드 세트(fold set)**으로 만들어주고, k개의 폴드 세트를 **train set(학습용)**과 **validation set(검증용)**으로 나누게 됩니다.\n",
        "\n",
        "k-1개를 학습 데이터셋으로, 1개를 검증 데이터셋으로 설정하여 검증 평가를 진행하는데, k개의 폴드 세트에 대해 차례로 검증 데이터셋을 변경하여 **k번의 검증**을 수행합니다.\n",
        "\n",
        "모델을 학습한 뒤, **k번의 성능 평가 결과를 평균**하여 최종 모델 성능을 구합니다."
      ],
      "metadata": {
        "id": "REN0UBxF-8l7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저 sklearn.model_selection에서 **kFold** 메서드를 import 해주었습니다."
      ],
      "metadata": {
        "id": "-XAsfFo5CBPM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gF8-dBLAyEU2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**n_splits**는 몇 개의 폴드(fold)로 나눌 것인지를 의미하는 매개변수로 사용자가 임의로 선택할 수 있습니다.\n",
        "\n",
        "5겹 교차 검증이 가장 일반적이라 저는 5를 넣어 kfold 객체를 생성해주었습니다."
      ],
      "metadata": {
        "id": "rDGZ5ckhCIZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=5)"
      ],
      "metadata": {
        "id": "-2HeETB3zFQC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "iris 피처 데이터셋과 레이블 데이터셋을 각각 feature 와 label로 지정해주었습니다."
      ],
      "metadata": {
        "id": "0b0cMLCR0vUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "feature = iris.data\n",
        "label = iris.target"
      ],
      "metadata": {
        "id": "nsLWr4OlClbP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "조건문을 활용하여 폴드 세트 별로 교차 검증의 정확도와 데이터셋의 활용이 어떻게 진행되는지 인덱싱을 나타내보겠습니다."
      ],
      "metadata": {
        "id": "lDsraeO-1A_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저 폴드 세트 별로 성능 평가 결과를 저장할 리스트 객체 **cv_accuracy**를 만들었고, 검증 횟수를 나타내는 **n_iter** 를 만들어주었습니다.\n",
        "\n",
        "그리고 의사결정나무 모델의 객체를 생성해주었습니다."
      ],
      "metadata": {
        "id": "sldreo7VzHqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_accuracy = []\n",
        "n_iter =0\n",
        "dt_clf = DecisionTreeClassifier(random_state=1)"
      ],
      "metadata": {
        "id": "fHjTFzkBzGv4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwUopBld5w-h",
        "outputId": "0b6e2cf4-bb2f-41fd-9763-7c7cbe651e7c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "피처 데이터셋이 150개이니, 5개의 폴드로 나누면 30개씩이겠군요.\n",
        "\n",
        "인덱스를 출력하여 직접 확인해보겠습니다!\n",
        "\n",
        "split 함수를 활용하면 kfold의 학습용 데이터 인덱스, 테스트용 데이터 인덱스를 ,array로 반환해줍니다.\n",
        "\n",
        "그리고 추출한 인덱스를 통해 데이터를 인덱싱하여 모델을 학습, 검증하는 과정을 거칩니다.\n",
        "\n",
        "마지막으로 폴드 세트 별로 정확도와 데이터 크기, 데이터 인덱스를 출력해보았습니다."
      ],
      "metadata": {
        "id": "BGYnc10Z1qQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_iter =0\n",
        "for train_index, test_index in kfold.split(feature):  \n",
        "    x_train, x_test = feature[train_index], feature[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    \n",
        "    dt_clf.fit(x_train, y_train)\n",
        "    pred = dt_clf.predict(x_test)\n",
        "    n_iter += 1\n",
        "    \n",
        "    accuracy = np.round(accuracy_score(y_test, pred), 4) \n",
        "    train_size = x_train.shape[0]\n",
        "    test_size = x_test.shape[0]\n",
        "    \n",
        "    print('\\n#{0} 교차 검증 정확도 : {1},  학습 데이터 크기 : {2},  검증 데이터 크기 : {3}'\n",
        "          .format(n_iter, accuracy, train_size, test_size))\n",
        "    print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter,test_index))\n",
        "    cv_accuracy.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6rhY4LwCfpK",
        "outputId": "d5bb4629-9260-445c-de70-be6a956804b8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#1 교차 검증 정확도 : 1.0,  학습 데이터 크기 : 120,  검증 데이터 크기 : 30\n",
            "#1 검증 세트 인덱스 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "#2 교차 검증 정확도 : 1.0,  학습 데이터 크기 : 120,  검증 데이터 크기 : 30\n",
            "#2 검증 세트 인덱스 : [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
            " 54 55 56 57 58 59]\n",
            "\n",
            "#3 교차 검증 정확도 : 0.9,  학습 데이터 크기 : 120,  검증 데이터 크기 : 30\n",
            "#3 검증 세트 인덱스 : [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
            " 84 85 86 87 88 89]\n",
            "\n",
            "#4 교차 검증 정확도 : 0.9333,  학습 데이터 크기 : 120,  검증 데이터 크기 : 30\n",
            "#4 검증 세트 인덱스 : [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
            "\n",
            "#5 교차 검증 정확도 : 0.7333,  학습 데이터 크기 : 120,  검증 데이터 크기 : 30\n",
            "#5 검증 세트 인덱스 : [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
            " 138 139 140 141 142 143 144 145 146 147 148 149]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "30개씩 5개의 세트로 나누어 30 단위씩 인덱스가 바뀌며 검증 데이터셋이 바뀌는 것을 볼 수 있습니다."
      ],
      "metadata": {
        "id": "Ja2FTWK663Lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그리고 5개의 폴드 세트에 대한 교차 검증 정확도를 평균내어 최종 모델 성능을 구해보았습니다."
      ],
      "metadata": {
        "id": "oYbrdvFK1wp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSGm4JmC1sVv",
        "outputId": "0f10eea6-d24f-4695-e8ef-4cb56c7673de"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## 평균 검증 정확도: 0.91332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "교차검증 이전의 정확도보다는 떨어졌지만, 과적합이 교정된 것으로 이해하면 될 것 같습니다."
      ],
      "metadata": {
        "id": "biA2mpbFGjJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. KFold의 문제점**\n",
        "\n",
        "KFold에는 약간의 문제점이 존재하는데, 먼저 KFold 는 데이터셋을 일정한 간격으로 쪼갭니다.\n",
        "\n",
        "가령 iris data set을 보면, 레이블이 0,1,2 세개가 존재하고 레이블 0인 데이터셋 50개, 1인 데이터셋 50개, 2인 데이터셋 50개의 순서로 이루어져있죠."
      ],
      "metadata": {
        "id": "bcXwCOPN7SGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "iris data set을 data frame으로 나타내보았습니다."
      ],
      "metadata": {
        "id": "jRP1XyHv9zah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DZyd3v6R9f-a",
        "outputId": "2d3fdd00-f9ec-43dd-f37b-18d39ac4ed0a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c918e31c-4d96-4572-abfc-ecc5df065f9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c918e31c-4d96-4572-abfc-ecc5df065f9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c918e31c-4d96-4572-abfc-ecc5df065f9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c918e31c-4d96-4572-abfc-ecc5df065f9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  ...  petal width (cm)  label\n",
              "0                  5.1               3.5  ...               0.2      0\n",
              "1                  4.9               3.0  ...               0.2      0\n",
              "2                  4.7               3.2  ...               0.2      0\n",
              "3                  4.6               3.1  ...               0.2      0\n",
              "4                  5.0               3.6  ...               0.2      0\n",
              "..                 ...               ...  ...               ...    ...\n",
              "145                6.7               3.0  ...               2.3      2\n",
              "146                6.3               2.5  ...               1.9      2\n",
              "147                6.5               3.0  ...               2.0      2\n",
              "148                6.2               3.4  ...               2.3      2\n",
              "149                5.9               3.0  ...               1.8      2\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "따라서, 분류한 폴드세트에서 학습 데이터셋의 레이블이 0, 1로만 이루어져있다면 데이터셋의 레이블이 2인 데이터는 올바르게 분류해낼 수 없습니다."
      ],
      "metadata": {
        "id": "TGfjEuLj9jVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold_1 = KFold(n_splits=3)\n",
        "n_iter_=0\n",
        "\n",
        "for train_index, test_index in kfold_1.split(iris_df):  \n",
        "    n_iter_+=1\n",
        "    train = iris_df['label'].iloc[train_index]\n",
        "    test = iris_df['label'].iloc[test_index]\n",
        "    \n",
        "    print('# 교차 검증:{}'.format(n_iter_))\n",
        "    print('# 학습 레이블 데이터 : \\n',train.value_counts())\n",
        "    print('# 검증 레이블 데이터 : \\n',test.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XVt1nrX97TA",
        "outputId": "12f82912-0bbf-43c2-c8b1-e6a3e1ce683d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# 교차 검증:1\n",
            "# 학습 레이블 데이터 : \n",
            " 1    50\n",
            "2    50\n",
            "Name: label, dtype: int64\n",
            "# 검증 레이블 데이터 : \n",
            " 0    50\n",
            "Name: label, dtype: int64\n",
            "# 교차 검증:2\n",
            "# 학습 레이블 데이터 : \n",
            " 0    50\n",
            "2    50\n",
            "Name: label, dtype: int64\n",
            "# 검증 레이블 데이터 : \n",
            " 1    50\n",
            "Name: label, dtype: int64\n",
            "# 교차 검증:3\n",
            "# 학습 레이블 데이터 : \n",
            " 0    50\n",
            "1    50\n",
            "Name: label, dtype: int64\n",
            "# 검증 레이블 데이터 : \n",
            " 2    50\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약 폴드 세트를 3개로 쪼갠다면, 이렇게 극단적인 모습으로 레이블 데이터가 나눠집니다."
      ],
      "metadata": {
        "id": "ZqV6JlcMCzI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "n_iter =0\n",
        "for train_index, test_index in kfold.split(feature):  \n",
        "    x_train, x_test = feature[train_index], feature[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    \n",
        "    dt_clf.fit(x_train, y_train)\n",
        "    pred = dt_clf.predict(x_test)\n",
        "    n_iter += 1\n",
        "    \n",
        "    accuracy = np.round(accuracy_score(y_test, pred), 4) \n",
        "    train_size = x_train.shape[0]\n",
        "    test_size = x_test.shape[0]\n",
        "    \n",
        "    print('\\n#{0} 교차 검증 정확도 : {1},  학습 데이터 크기 : {2},  검증 데이터 크기 : {3}'\n",
        "          .format(n_iter, accuracy, train_size, test_size))\n",
        "    print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter,test_index))\n",
        "    cv_accuracy.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgDHZ_L1JF0-",
        "outputId": "e5667870-cdfc-4a9c-d60e-577f1ec8f321"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#1 교차 검증 정확도 : 0.0,  학습 데이터 크기 : 100,  검증 데이터 크기 : 50\n",
            "#1 검증 세트 인덱스 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49]\n",
            "\n",
            "#2 교차 검증 정확도 : 0.0,  학습 데이터 크기 : 100,  검증 데이터 크기 : 50\n",
            "#2 검증 세트 인덱스 : [50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n",
            " 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
            " 98 99]\n",
            "\n",
            "#3 교차 검증 정확도 : 0.0,  학습 데이터 크기 : 100,  검증 데이터 크기 : 50\n",
            "#3 검증 세트 인덱스 : [100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
            " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
            " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그리고... 교차 검증의 정확도 또한 보시다시피 0이 됩니다."
      ],
      "metadata": {
        "id": "rDv6deCwJL2R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 KFold는 데이터 편향이 존재하는 경우, 제대로된 모델 학습과 검증이 이루어지지 않을 수 있습니다.\n",
        "\n",
        "이를 해결할 수 있는 방법에는 다양한 방법들이 있지만, 먼저 간단하게 KFold 메서드 내에서 매개변수 **suffle**을 **True**로 설정해줄 수 있습니다.\n",
        "\n",
        "데이터셋을 섞어주는 것이죠."
      ],
      "metadata": {
        "id": "EFg3Xt_bDRjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True)\n",
        "n_iter =0\n",
        "for train_index, test_index in kfold.split(feature):  \n",
        "    x_train, x_test = feature[train_index], feature[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    \n",
        "    dt_clf.fit(x_train, y_train)\n",
        "    pred = dt_clf.predict(x_test)\n",
        "    n_iter += 1\n",
        "    \n",
        "    accuracy = np.round(accuracy_score(y_test, pred), 4) \n",
        "    train_size = x_train.shape[0]\n",
        "    test_size = x_test.shape[0]\n",
        "    \n",
        "    print('\\n#{0} 교차 검증 정확도 : {1},  학습 데이터 크기 : {2},  검증 데이터 크기 : {3}'\n",
        "          .format(n_iter, accuracy, train_size, test_size))\n",
        "    print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter,test_index))\n",
        "    cv_accuracy.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUoBdZmkJYOR",
        "outputId": "423f78b9-028b-4ef1-d701-3438879b1025"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#1 교차 검증 정확도 : 0.92,  학습 데이터 크기 : 100,  검증 데이터 크기 : 50\n",
            "#1 검증 세트 인덱스 : [  0   3   4   9  11  14  17  20  22  23  24  26  27  31  35  38  39  45\n",
            "  47  50  56  57  62  65  67  75  76  79  80  81  84  90  91  94  98 102\n",
            " 103 104 105 107 108 112 113 119 129 135 136 138 144 147]\n",
            "\n",
            "#2 교차 검증 정확도 : 0.94,  학습 데이터 크기 : 100,  검증 데이터 크기 : 50\n",
            "#2 검증 세트 인덱스 : [  2   6   7   8  15  18  30  32  33  43  46  51  53  55  59  61  64  66\n",
            "  69  70  74  77  78  82  83  85  89  93  97  99 106 109 110 117 120 121\n",
            " 122 123 124 125 126 128 130 132 134 137 139 140 148 149]\n",
            "\n",
            "#3 교차 검증 정확도 : 0.98,  학습 데이터 크기 : 100,  검증 데이터 크기 : 50\n",
            "#3 검증 세트 인덱스 : [  1   5  10  12  13  16  19  21  25  28  29  34  36  37  40  41  42  44\n",
            "  48  49  52  54  58  60  63  68  71  72  73  86  87  88  92  95  96 100\n",
            " 101 111 114 115 116 118 127 131 133 141 142 143 145 146]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " shuffle을 사용하여 데이터셋을 섞었기 때문에 index를 보면 순서대로가 아닌 임의로 데이터가 분배되었음을 확인할 수 있습니다.\n",
        "\n",
        "다행히도 아까와 달리 모델의 학습과 검증이 나름 잘 일어난 것을 볼 수 있습니다."
      ],
      "metadata": {
        "id": "fGgMx5y6JdeJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Stratified K-Fold Cross Validation(계층별 k-겹 교차 검증)**\n",
        "\n",
        "이러한 문제점을 해결하기 위한 또 다른 방법이 바로 **Stratified K-Fold Cross Validation(계층별 k-겹 교차 검증)**인데요.\n",
        "\n",
        "계층별 k-겹 교차 검증은 원본 데이터의 전체 **레이블 분포**를 학습 및 검증 데이터셋에 반영해줍니다.\n",
        "\n",
        "가령 iris data set 에서 레이블 0,1,2가 1:1:1 의 비율로 데이터가 분포되어있다면 학습데이터와 검증데이터의 레이블 분포도 0,1,2가 각각 1:1:1을 모두 따르게 되는 것이죠.\n",
        "\n",
        "따라서 학습 데이터셋과 검증 데이터셋은 레이블 분포가 유사하도록 데이터셋을 분배하기 때문에, 데이터의 편향으로 인한 문제점을 방지할 수 있습니다.\n",
        "\n",
        "코드를 통해 계층별 K겹 교차 검증을 구현해볼텐데요, 사용법은 KFold와 동일합니다!"
      ],
      "metadata": {
        "id": "6mu7o6uhJXso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저, **StratifiedKFold** 메서드를 import 해주었습니다."
      ],
      "metadata": {
        "id": "3qt8Yj1LM2Ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "metadata": {
        "id": "fRG3Cij_Mwnz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "S_kfold라는 계층별 5겹 교차검증 객체를 생성해주었습니다."
      ],
      "metadata": {
        "id": "JIEZAbQ4O-CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "S_kfold = StratifiedKFold(n_splits=5)"
      ],
      "metadata": {
        "id": "Jd418MihMtMh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KFold와 동일하게, 폴드별로 정확도와 인덱스를 확인해보겠습니다."
      ],
      "metadata": {
        "id": "jkN_U2KxPHA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_accuracy = []\n",
        "n_iter =0\n",
        "\n",
        "for train_index, test_index in S_kfold.split(feature, label):  \n",
        "    x_train, x_test = feature[train_index], feature[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    \n",
        "    dt_clf.fit(x_train, y_train)\n",
        "    pred = dt_clf.predict(x_test)\n",
        "    n_iter += 1\n",
        "    \n",
        "    accuracy = np.round(accuracy_score(y_test, pred), 4) \n",
        "    train_size = x_train.shape[0]\n",
        "    test_size = x_test.shape[0]\n",
        "    \n",
        "    print('\\n#{0} 교차 검증 정확도 : {1},  학습 데이터 크기 : {2},  검증 데이터 크기 : {3}'\n",
        "          .format(n_iter, accuracy, train_size, test_size))\n",
        "    print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter,test_index))\n",
        "    cv_accuracy.append(accuracy)\n",
        "    \n",
        "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxrAOyRRM8KR",
        "outputId": "0c762f86-d094-4f3b-8cef-0acd6270ff04"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#1 교차 검증 정확도 : 0.9667,  학습 데이터 크기 : 120,  검증 데이터 크기 : 30\n",
            "#1 검증 세트 인덱스 : [  0   1   2   3   4   5   6   7   8   9  50  51  52  53  54  55  56  57\n",
            "  58  59 100 101 102 103 104 105 106 107 108 109]\n",
            "\n",
            "#2 교차 검증 정확도 : 0.9667,  학습 데이터 크기 : 120,  검증 데이터 크기 : 30\n",
            "#2 검증 세트 인덱스 : [ 10  11  12  13  14  15  16  17  18  19  60  61  62  63  64  65  66  67\n",
            "  68  69 110 111 112 113 114 115 116 117 118 119]\n",
            "\n",
            "#3 교차 검증 정확도 : 0.9,  학습 데이터 크기 : 120,  검증 데이터 크기 : 30\n",
            "#3 검증 세트 인덱스 : [ 20  21  22  23  24  25  26  27  28  29  70  71  72  73  74  75  76  77\n",
            "  78  79 120 121 122 123 124 125 126 127 128 129]\n",
            "\n",
            "#4 교차 검증 정확도 : 1.0,  학습 데이터 크기 : 120,  검증 데이터 크기 : 30\n",
            "#4 검증 세트 인덱스 : [ 30  31  32  33  34  35  36  37  38  39  80  81  82  83  84  85  86  87\n",
            "  88  89 130 131 132 133 134 135 136 137 138 139]\n",
            "\n",
            "#5 교차 검증 정확도 : 1.0,  학습 데이터 크기 : 120,  검증 데이터 크기 : 30\n",
            "#5 검증 세트 인덱스 : [ 40  41  42  43  44  45  46  47  48  49  90  91  92  93  94  95  96  97\n",
            "  98  99 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 평균 검증 정확도: 0.96668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "평균 검증 정확도가 눈에 띄게 상승했습니다!\n",
        "\n",
        "그럼 레이블 분포가 학습 데이터셋과 검증 데이터셋에 어떻게 분포되어있는지 확인해보겠습니다."
      ],
      "metadata": {
        "id": "OSO2k-x-POWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnC3af9kPglL",
        "outputId": "8eacfab6-3a54-431b-9cb4-aa08f6b24245"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    50\n",
              "1    50\n",
              "2    50\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체 데이터셋은 레이블 0, 1, 2가 각각 1:1:1로 분포되어 있네요."
      ],
      "metadata": {
        "id": "h5PA4HmRPo9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skfold_1 = StratifiedKFold(n_splits=5)\n",
        "n_iter_=0\n",
        "\n",
        "for train_index, test_index in skfold_1.split(iris_df, iris_df['label']):  \n",
        "    n_iter_+=1\n",
        "    train = iris_df['label'].iloc[train_index]\n",
        "    test = iris_df['label'].iloc[test_index]\n",
        "    \n",
        "    print('# 교차 검증:{}'.format(n_iter_))\n",
        "    print('# 학습 레이블 데이터 : \\n',train.value_counts())\n",
        "    print('# 검증 레이블 데이터 : \\n',test.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlEwDhgtNVIh",
        "outputId": "5fcdb0f4-cf7e-46c9-fd31-7f7cdb60ff4d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# 교차 검증:1\n",
            "# 학습 레이블 데이터 : \n",
            " 0    40\n",
            "1    40\n",
            "2    40\n",
            "Name: label, dtype: int64\n",
            "# 검증 레이블 데이터 : \n",
            " 0    10\n",
            "1    10\n",
            "2    10\n",
            "Name: label, dtype: int64\n",
            "# 교차 검증:2\n",
            "# 학습 레이블 데이터 : \n",
            " 0    40\n",
            "1    40\n",
            "2    40\n",
            "Name: label, dtype: int64\n",
            "# 검증 레이블 데이터 : \n",
            " 0    10\n",
            "1    10\n",
            "2    10\n",
            "Name: label, dtype: int64\n",
            "# 교차 검증:3\n",
            "# 학습 레이블 데이터 : \n",
            " 0    40\n",
            "1    40\n",
            "2    40\n",
            "Name: label, dtype: int64\n",
            "# 검증 레이블 데이터 : \n",
            " 0    10\n",
            "1    10\n",
            "2    10\n",
            "Name: label, dtype: int64\n",
            "# 교차 검증:4\n",
            "# 학습 레이블 데이터 : \n",
            " 0    40\n",
            "1    40\n",
            "2    40\n",
            "Name: label, dtype: int64\n",
            "# 검증 레이블 데이터 : \n",
            " 0    10\n",
            "1    10\n",
            "2    10\n",
            "Name: label, dtype: int64\n",
            "# 교차 검증:5\n",
            "# 학습 레이블 데이터 : \n",
            " 0    40\n",
            "1    40\n",
            "2    40\n",
            "Name: label, dtype: int64\n",
            "# 검증 레이블 데이터 : \n",
            " 0    10\n",
            "1    10\n",
            "2    10\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과를 보니, 모든 학습 데이터셋과 검증 데이터셋에서 0, 1, 2 각각의 레이블이 1:1:1로 분포하고 있습니다!"
      ],
      "metadata": {
        "id": "fVjt-RUsPWWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 이번 게시물에서는 KFold 와 Stratified K-Fold 교차검증법을 구현해보았습니다.\n",
        "\n",
        "정확하고 성능 좋은 모델을 위해서는 교차검증법이 필수적인 것 같아요!\n",
        "\n",
        "다음 포스팅에서는 다른 교차검증법들을 실습해보겠습니다!\n",
        "\n",
        "읽어주셔서 감사합니다:)"
      ],
      "metadata": {
        "id": "TOYNY5kuPt9A"
      }
    }
  ]
}