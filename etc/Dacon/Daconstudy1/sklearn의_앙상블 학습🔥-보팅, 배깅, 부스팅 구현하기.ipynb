{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "앙상블.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "안녕하세요! \n",
        "\n",
        "데이크루 1기로 활동 중인 sssssun입니다!\n",
        "\n",
        "계속해서 sklearn을 활용하여 머신러닝 모델의 성능을 높이는 법을 공부하고 있는데요.\n",
        "\n",
        "이번 포스팅은 \"**앙상블 학습(Ensemble Learning)**\"에 대해 다루어보려고 합니다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sGiEH65uFidy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **앙상블 학습(Ensemble Learning)**\n",
        "\n",
        "앙상블 학습(Ensemble Learning)은 여러 개의 분류기를 생성하고, 그 예측을 결합함으로써 보다 정확한 예측을 도출하는 기법을 말합니다.\n",
        "\n",
        "회귀 모델이든 분류 모델이든, 하나의 모델을 사용하기 보다는 모델 여러 개를 조합하여 더 정확한 예측에 도움을 주는 방식입니다.\n",
        "\n",
        "구체적으로 여러 개의 약 분류기 (Weak Classifier)를 결합하여 강 분류기(Strong Classifier)를 만들어 모델의 정확성을 향상시킵니다.\n",
        "\n",
        "예를 들어 보면, 어떤 문제를 해결하는 데 있어서 한 명의 전문가보다는 여러 명의 비전문가 일반인이 집단지성을 이용하여 문제를 해결하는 방식이 나을 수도 있습니다.\n",
        "\n",
        "이게 바로 앙상블 기법이라고 할 수 있죠.\n",
        "\n",
        "실제로 머신러닝 대회에서 우승하는 솔루션들은 대부분 앙상블 기법을 활용해 고성능을 낸다고 합니다."
      ],
      "metadata": {
        "id": "WgCPane9JTwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **앙상블 학습 유형**\n",
        "\n",
        "앙상블 학습은 크게 보팅(Voting), 배깅(Bagging), 부스팅(Boosting)으로 나눌 수 있습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "HbTJzkTdK0xN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. 보팅(Voting)**\n",
        "\n",
        "말 그대로 여러 개의 분류기가 투표를 통해 최종 예측 결과를 결정하는 방식입니다.\n",
        "\n",
        "서로 다른 알고리즘을 여러 개 결합하여 사용하게 됩니다.\n",
        "\n",
        "- **하드 보팅(Hard Voting)**\n",
        "\n",
        ": 다수의 분류기가 예측한 결과값을 최종 결과로 선정, 즉 다수결의 원칙을 따릅니다.\n",
        "\n",
        "- **소프트 보팅(Soft Voting)**\n",
        "\n",
        ": 모든 분류기가 예측한 레이블 값의 결정 확률 평균을 구한 뒤 가장 확률이 높은 레이블 값을 최종 결과로 선정합니다."
      ],
      "metadata": {
        "id": "Ml_YeElpU_MZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sklearn의 유방암 데이터셋을 활용하여 보팅 방식의 앙상블 학습을 구현해보겠습니다.\n",
        "\n",
        "라이브러리를 import 해주었고, 데이터셋을 불러왔습니다."
      ],
      "metadata": {
        "id": "vJ4T8r78NoTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "JAVVpH_ENkk1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YTf2lLy-FXUG"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "cancer = load_breast_cancer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cancer = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "cancer.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "YgnnnFljOgw9",
        "outputId": "072885c3-5cf1-45d8-ad32-3ebe51c585d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e588b631-85a4-4180-bbac-45b79cb9f0ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e588b631-85a4-4180-bbac-45b79cb9f0ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e588b631-85a4-4180-bbac-45b79cb9f0ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e588b631-85a4-4180-bbac-45b79cb9f0ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "3        11.42         20.38  ...          0.6638                  0.17300\n",
              "4        20.29         14.34  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그리고 데이터셋까지 훈련 데이터셋과 테스트 데이터셋으로 나눠주었습니다."
      ],
      "metadata": {
        "id": "vlKFOey6Rvjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2 , random_state= 156)"
      ],
      "metadata": {
        "id": "ruLhRt3MRtaz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sklearn의 보팅 분류기, **VotingClassifier** 를 활용해보겠습니다.\n",
        "\n",
        "그리고 보팅 분류기에 넣을 개별 모델은 **로지스틱 회귀 모델**과 **KNN 모델**을 선택해주었습니다."
      ],
      "metadata": {
        "id": "ZAVg06xZOo-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "9x-zrHswOfIo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "로지스틱 회귀와 KNN을 각각 객체 지정해주고, 둘다 VotingClassifier에 넣어줍니다.\n",
        "\n",
        "voting 매개변수를 통해 타입을 선택해줄 수 있는데, 저는 **soft voting** 으로 해주었습니다."
      ],
      "metadata": {
        "id": "V90mY7abQyAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "knn = KNeighborsClassifier(n_neighbors=8)\n",
        "\n",
        "V_clf = VotingClassifier( estimators=[('LR',lr),('KNN',knn)] , voting='soft' )"
      ],
      "metadata": {
        "id": "Sjs-8lyQNTal"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "그리고 다른 알고리즘을 학습하는 것처럼, VotingClassifier 또한 학습, 예측 그리고 평가의 과정을 거쳐줍니다."
      ],
      "metadata": {
        "id": "sE9ghCvtSNQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "V_clf.fit(X_train , y_train)\n",
        "pred = V_clf.predict(X_test)\n",
        "print('VotingClassifier 정확도: ', round(accuracy_score(y_test , pred),4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb0rADj2Qs5u",
        "outputId": "bea2b807-28c2-4684-f33a-7d4640af83d8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VotingClassifier 정확도:  0.9474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "로지스틱 회귀 모델, KNN 모델 각각 한가지만 활용했을 때 정확도를 구해보겠습니다."
      ],
      "metadata": {
        "id": "ZeXQIPY4Tc_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [lr, knn]\n",
        "for model in models:\n",
        "    model.fit(X_train , y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    name = model.__class__.__name__\n",
        "    print('{0} 정확도: {1:.4f}'.format(name, accuracy_score(y_test , pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SOZuC9DSzwP",
        "outputId": "18afae1b-c381-49db-8fd5-c105f8ac5f4d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 정확도: 0.9386\n",
            "KNeighborsClassifier 정확도: 0.9386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "즉, VotingClassifier를 사용하였을 때는 정확도가 0.9474, 나머지 모델들을 한 개씩만 이용하였을 때는 정확도가 0.9386이 나오네요.\n",
        "\n",
        "보팅 분류기를 이용하는 것이 더 정확도가 높은 것을 볼 수 있었습니다."
      ],
      "metadata": {
        "id": "adMuPanxTzmB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. 배깅(Bagging)**\n",
        "\n",
        "배깅은 간단히 말해 **훈련 세트의 중복을 허용하여 샘플링**을 하는 방식입니다. \n",
        "\n",
        "통계학에서는 \"부트스트래핑\"이라고 부르는데,\n",
        "\n",
        "각 모델이 서로 다른 학습데이터셋을 이용해야하고, 데이터 셋을 뽑을때는 복원추출을 한다는 점, 그리고 원 데이터 수만큼 데이터 셋을 뽑아야 합니다.\n",
        "\n",
        "배깅은 다음과 같은 과정을 거칩니다!\n",
        "\n",
        "1. 동일한 알고리즘을 사용하는 일정 수의 분류기를 생성합니다.\n",
        "\n",
        "2. 각각의 분류기에 부트스트래핑 분할 방식으로 생성된 샘플데이터를 학습합니다.\n",
        "\n",
        "3. 최종적으로 각각의 결과를 보팅(Voting)을 통해 예측 결정합니다.\n"
      ],
      "metadata": {
        "id": "Xo6mvP9bWJNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **랜덤 포레스트(Random Forest)**\n",
        "\n",
        "배깅의 대표적인 알고리즘은 **랜덤 포레스트**입니다.\n",
        "\n",
        "랜덤 포레스트는 여러 개의 결정 트리 분류기가 전체 데이터에서 배깅 방식으로 각자의 데이터를 샘플링합니다.\n",
        "\n",
        "그리고 개별적으로 학습을 수행하고, 최종적으로 모든 분류기가 보팅을 통해 예측 결정을 합니다."
      ],
      "metadata": {
        "id": "BOmyeXfwZn_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2 , random_state= 156)"
      ],
      "metadata": {
        "id": "kgIy0l-YcAcg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RandomForestClassifier를 import 해주었습니다."
      ],
      "metadata": {
        "id": "Dut5E03-fG8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "HTXPFglpcCoP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "사용법은 하나의 알고리즘과 동일하게 객체 지정, 학습, 예측의 과정을 거쳐주면 됩니다."
      ],
      "metadata": {
        "id": "KVLgl-cPe1yY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators=300, max_depth=20,random_state=0)\n",
        "clf.fit(X_train,y_train)\n",
        "pred1 = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "jMTTM5t-cGof"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('RandomForestClassifier 정확도: ', round(accuracy_score(y_test,pred1),4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHUrzcN7cuvv",
        "outputId": "e7f72a36-db9f-4c09-b594-b408d45b69bc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier 정확도:  0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정확도가 0.9561 이네요. 보팅 분류기보다 높습니다."
      ],
      "metadata": {
        "id": "yukzVRHqfKnt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤 포레스트는 다양한 하이퍼 파라미터를 갖기 때문에, 하이퍼 파라미터 튜닝을 해주면 더 좋은데요.\n",
        "\n",
        "마침 지난 포스팅에서 다뤘던 GridSearchCV를 이용한 하이퍼 파라미터 튜닝을 해보겠습니다.\n"
      ],
      "metadata": {
        "id": "pBDEhs-ThyfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "    'n_estimators':[100],\n",
        "    'max_depth' : [6, 8, 10, 12], \n",
        "    'min_samples_leaf' : [8, 12, 18 ],\n",
        "    'min_samples_split' : [8, 16, 20]\n",
        "}\n",
        "\n",
        "\n",
        "rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
        "grid_cv = GridSearchCV(rf_clf , param_grid=params , cv=2, n_jobs=-1 )\n",
        "grid_cv.fit(X_train , y_train)\n",
        "\n",
        "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
        "print('\\n최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYZnLhurh4FJ",
        "outputId": "b310ec24-f264-4744-d64b-9342599b8ca7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적 하이퍼 파라미터:\n",
            " {'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 100}\n",
            "\n",
            "최고 예측 정확도: 0.9451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. 부스팅(Boosting)**\n",
        "\n",
        "\n",
        "부스팅은 여러 개의 약한 학습기(weak learner)를 순차적으로 학습-예측하면서 잘못 예측한 데이터에 가중치를 부여해 오류를 개선해나가며 학습하는 방식입니다.\n",
        "\n",
        "부스팅(Boosting)은 편향(bias)이 높은 경우 이를 낮추는 것과 같이 성능 자체를 강화하는데 목적을 둡니다. "
      ],
      "metadata": {
        "id": "Ms0YbtChgXq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "부스팅 알고리즘은 대표적으로 다음과 같은 알고리즘이 있습니다.\n",
        "\n",
        "- AdaBoost\n",
        "- Gradient Booting Machine(GBM)\n",
        "- XGBoost\n",
        "- LightGBM\n",
        "- CatBoost\n",
        "\n",
        "다른 분들의 코드에서 많이 보았던 알고리즘들인 것 같아요!"
      ],
      "metadata": {
        "id": "T0fF6b__jzlp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사용법은 랜덤 포레스트 및 다른 알고리즘들과 동일합니다.\n",
        "\n",
        "AdaBoostClassifier와 GradientBoostingClassifier를 구현해보겠습니다."
      ],
      "metadata": {
        "id": "Ek28xPkSkc8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "\n",
        "clf = AdaBoostClassifier(n_estimators=30, random_state=10, learning_rate=0.1)\n",
        "clf.fit(X_train, y_train)\n",
        "pred2 = clf.predict(X_test)\n",
        "\n",
        "print('AdaBoost 정확도: ', round(accuracy_score(y_test,pred2),4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWBaCtQUkiPG",
        "outputId": "8ee155f5-2ca1-478b-dfb1-f8ae30e9508a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost 정확도:  0.9474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier \n",
        "\n",
        "\n",
        "gb_clf = GradientBoostingClassifier(random_state=0)\n",
        "gb_clf.fit(X_train, y_train)\n",
        "pred3 = gb_clf.predict(X_test)\n",
        "gb_accuracy = accuracy_score(y_test, pred3)\n",
        "\n",
        "print('GBM 정확도: ', round(accuracy_score(y_test,pred3),4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OhFvcemkkKG",
        "outputId": "486fe5d8-99e9-4d85-9381-25b2a0c9007a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GBM 정확도:  0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GBM과 랜덤포레스트를 이용했을 때 정확도가 0.9561로 가장 높습니다.\n",
        "\n",
        "데이터에 따라서 앙상블 방법을 여러가지 시도해보고 선택하면 좋을 것 같아요.\n",
        "\n",
        "읽어주셔서 감사합니다:)"
      ],
      "metadata": {
        "id": "KsBpc8DnlwyK"
      }
    }
  ]
}